## OSI 7层

见图

![点击查看源网页](https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3468133779,3831121784&fm=26&gp=0.jpg)

OSI 7层 **记忆口诀**：

`All People Same To Need Data Process (所有的人都需要对数据处理)`

每个单词对应一层,他们开头字母一样，分别是应用层(Application), 表示层(Presentation), 会话层(Session), 网络层(Network), 数据链路层(Data Link), 物理层(Physical)

### 应用层

应用层为操作系统或网络应用程序提供访问网络服务的接口

应用层协议的代表包括：**Telnet、FTP、HTTP、SNMP**等

### 表示层

表示层对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。

表示层协议的代表包括：**ASCII、ASN.1、JPEG、MPEG**等。

### 会话层

会话层管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。

会话层协议的代表包括：**NetBIOS、ZIP**（**AppleTalk**区域信息协议）等。

### 传输层

传输层是第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。

在这一层，**数据的单位**称为**数据段**（segment）。

传输层协议的代表包括：**TCP、UDP、SPX**等。

### 网络层

网络层负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能。

在这一层，**数据的单位**称为**数据包**（packet）。

网络层协议的代表包括：**IP、IPX、RIP、OSPF**等。

### 数据链路层

数据链路层在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。

在这一层，**数据的单位**称为**帧**（frame）。

数据链路层协议的代表包括：**SDLC、HDLC、PPP、STP、帧中继**等。

### 物理层

物理层规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的物理媒体。

在这一层，**数据的单位**称为**比特**（bit）。

属于物理层定义的典型规范代表包括：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45等。

### 附图

![image-20200921233414886](../我的后端校招.assets/image-20200921233414886.png)

### 参考

https://blog.csdn.net/yaopeng_2005/article/details/7064869

https://www.jianshu.com/p/7bcd3ecf6acd

---



## IP



### 参考



---



## TCP

如果要用一句话来描述 TCP 协议，我想应该是：TCP 是一个**可靠的（reliable）**、**面向连接的（connection-oriented）**、**基于字节流（byte-stream）**、**全双工的（full-duplex）**协议。

### 什么是字节流？

TCP 是一种字节流（byte-stream）协议，流的含义是没有固定的报文边界。当接收方从 TCP 套接字读数据时，它是没法得知对方每次写入的字节是多少的。接收端可能分2 次每次 650 字节读取，也有可能先分三次，一次 100 字节，一次 200 字节，一次 1000 字节进行读取。

### 什么是全双工？

在 TCP 中发送端和接收端可以是客户端/服务端，也可以是服务器/客户端，通信的双方在任意时刻既可以是接收数据也可以是发送数据，每个方向的数据流都独立管理序列号、滑动窗口大小、MSS 等信息。

### 什么是面向连接，什么是无连接呢？

- 面向连接（connection-oriented）：面向连接的协议要求正式发送数据之前需要通过「握手」建立一个 **逻辑** 连接，结束通信时也是通过有序的四次挥手来断开连接。
- 无连接（connectionless）：无连接的协议则不需要

### TCP 头部结构和字段

TCP 数据封装在一个IP数据报中：

![img](https://upload-images.jianshu.io/upload_images/5679451-0d412b6d15dd7c49.png?imageMogr2/auto-orient/strip|imageView2/2)

下图是TCP报文数据格式。TCP首部如果不计选项和填充字段，它通常是20个字节。

![img](https://upload-images.jianshu.io/upload_images/5679451-80b421b7c501a6ff.png?imageMogr2/auto-orient/strip|imageView2/2)

- **源端口和目的端口**：各占2个字节(byte)，这两个值与IP报文中的源端IP地址和目的端IP地址唯一确定一个TCP连接。有时一个IP地址和一个端口号也成为 socket(插口)
- **序号**：占4个字节，是本报文段(segment)所发送的数据项目组第一个字节的序号。在TCP传送的数据流中，每一个字节都有一个序号。例如，一报文段的序号为300，而且数据共100字节，则下一个报文段的序号就是400；序号是32bit的无符号数，序号到达2^32-1后从0开始。（注：如何防止从0开始后序号相同的问题）
- **确认序号**：占4个字节，是期望收到对方下次发送的数据的第一个字节的序号，也是期望收到的下一个报文段的首部中的序号；确认序号应该是上次已成功收到数据字节序号+1。<u>只有 ACK 标志为1时，确认序号才有效。</u>
- **数据偏移**：占4比特，表示数据开始的地方离TCP段的起始处有多远。实际上就是TCP 段首部的长度。由于首部长度不固定，因此数据偏移字段时必要的。数据偏移以32位为长度单位也就是4个字节，因此TCP首部的最大长度时60个字节。即便宜最大为12个长度单位=1532位=154字节
- **保留**：6比特，供以后应用，现在置位0.
- **6个标志位比特**：
  - URG：当此标志位值为1时，注解此报文应该尽快发送，而不要按本来的列队次序来传送。与“紧急指针”字段共同应用，紧急指针指出在本报文段中的紧急数据的最后一个字节的序号，使接管方可以知道紧急数据共有多长。
  - ACK：当此标志位值为1时，表示报文中确认序号字段才有效。（报文为确认报文）
  - PSH：当此标志位值为1时，接收方应该尽快将本报文段传送给应用层
  - RST：当此标志位值为1时，表示出现连接错误，必须释放连接，然后再重新传输连接。复位比特还用来拒绝一个不合法的报文段或拒绝打开一个连接。
  - SYN：当此标志位为1，ACK为0 时，表示请求建立一个连接，携带SYN标志的TCP报文段为同步报文段。
  - FIN：发送端完成发送任务
- **窗口**：TCP通过滑动窗口的概念来进行流量控制。设想在发送端发送数据的速度很快而接收端接收速度却很慢的情况下，为了保证数据不丢失，显然需要进行流量控制， 协调好通信双方的工作节奏。<u>所谓滑动窗口，可以理解成接收端所能提供的缓冲区大小</u>。TCP利用一个滑动的窗口来告诉发送端对它所发送的数据能提供多大的缓冲区。窗口大小为字节数，起始于确认序号字段指明的值（这个值是接收端正期望接收的字节）。窗口大小是一个16bit字段，因而窗口大小最大为65535字节。
- **检验和**：检验和覆盖了整个TCP报文段：TCP首部和数据。这是一个强制性的字段，一定时由发端计算和存储，并由收端验证。
- **紧急指针**：只有当URG标志位为1时紧急指针才有效。紧急指针是一个正的偏移量，和序列号字段中的值相加表示紧急数据最后一个字节的序号。

### TCP 三次握手过程

![img](../我的后端校招.assets/5679451-35449f2dcf275c3e.png)

1. 客户端向服务器发出连接请求报文，这时报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=J ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。
2. TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=J+1，同时也要为自己初始化一个序列号 seq=K，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。
3. TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=K+1，**[自己的序列号seq=J+1]**，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。
4. 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。

#### TCP 三次握手问题补充

- 为什么需要三次握手

  首先我们要知道<u>信道是不可靠的</u>，但是我们<u>要建立可靠的连接发送可靠的数据</u>，也就是<u>数据传输是需要可靠的</u>。在这个时候三次握手是一个理论上的最小值，并不是说是tcp协议要求的，而是为了满足在不可靠的信道上传输可靠的数据所要求的。

  这里举一个我最喜欢的例子，有A，B两个部落要攻打一个很强大的某国，只有当A、B两个部落同时对某国发起进攻才能把某国打下来，于是A派出信使悄悄的走小路去告诉B，我们明天X点一起发起进攻。A部落的信使（带着SYN=1，seq=J）来到了B部落告诉了B部落的人，然后B部落让信使回去告诉A部落他们知道了（ACK=1，SYN=1，ack=J+1，seq=K），信使回到了A部落，但是这样的一次通信是不可靠的，因为B部落的人不知道信使是不是安全到达了A部落把他们确认的信息传达了过去，所以，A部落再派信使跑了一趟告诉B部落没问题了明天见（ACK=1， ack=K+1） 所以三次握手是建立可靠连接理论上的最小值。
      在《计算机网络》一书中其中有提到，三次握手的目的是“为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误”，这种情况是：一端(client)A发出去的第一个连接请求报文并没有丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同意建立连接。如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。如果采用“三次握手”的话就不会出现这种情况，B端收到一个过时失效的报文段之后，向A端发出确认，此时A并没有要求建立连接，所以就不会向B端发送确认，这个时候B端也能够知道连接没有建立。

### TCP 四次挥手过程

![img](../我的后端校招.assets/5679451-47092d7c77d43ef7.png)

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。

5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

#### TCP 四次挥手问题补充

- 为什么需要四次挥手？

  为了确保数据能够完成传输。

  关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你未必会马上关闭Socket，也就是说你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

- 释放连接时为什么TIME-WAIT状态必须等待2MSL时间？

  首先说一下什么时MSL：

  MSL是 Maximum Segment Lifetime（报文最大生存时间），他是任何报文在网络上存在的最长时间，超过自个儿时间报文将会被丢弃。

  1） 为了保证A发送的最后一个ACK报文能够到达B。这个ACK报文段可能丢失，因而让处于LAST-ACK状态的B收不到已发送FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到重传的FIN+ACK报文段，重置时间等待计时器（2MSL）。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到B重传的FIN+ACK报文段，因而不会再发送一次确认报文段，这样B就无法正常进入CLOSED状态

  2） A在发送完ACK报文段后，经过2MSL时间，就可以使本链接持续的时间产生的所有报文段都从网络中小时。这样就可以使下一个生成的新连接中不会出现旧的连接请求的报文段。

- 客户端突然挂掉怎么办？

  正常连接时，客户端突然挂掉，如果灭有措施处理这种情况，那么就会出现客户端和服务器端出现长时间的空闲。解决办法时在服务器设置保活计时器，每当服务器收到客户端的消息，就将计时器复位。超时时长通常设置为2小时。若服务器超过2小时没有收到客户端的消息，他就发送探测报文段。若发送了1个探测报文段，每一个间隔75妙，还没有响应就会认为客户端除了故障，因而终止该连接。

### TCP 如何确保可靠性的？

TCP 要想在 IP 基础上构建可靠的传输层协议，必须有一个复杂的机制来保障可靠性。 主要有下面几个方面：

- 对每个包提供校验和
  - 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。
- 包的序列号解决了接收数据的乱序、重复问题
  - 将一个打包切分成小包并按序列排好顺序，接收方会根据序列号将数据排序
  - 如果 TCP 接收到重复的数据，可能的原因是超时重传了两次但这个包并没有丢失，接收端会收到两次同样的数据，它能够根据包序号丢弃重复的数据。
- 超时重传
  - 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。
- 流量控制、拥塞控制

### TCP 流量控制、滑动窗口

**流量控制**

TCP 流量控制主要时针对接收端的处理速度不如发送端发送速度的快，消除发送方使接收方缓存溢出的可能性。

TCP流量控制主要使用**滑动窗口协议**，滑动窗口是接收数据端使用的窗口大小，用来告诉发送端接收端的缓存大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的。

接收端通过TCP首部的窗口大小字段反馈当前可接收的字节数。

![img](../我的后端校招.assets/5679451-f32cc72ee6874f6d.png)

- 发送方接收到了对方发来的报文 ack = 33, win = 10，知道对方收到了 33 号前的数据，现在期望接收 [33, 43) 号数据。发送方连续发送了 4 个报文段假设为 A, B, C, D, 分别携带 [33, 35), [35, 36), [36, 38), [38, 41) 号数据。
- 接收方接收到了报文段 A, C，但是没收到 B 和 D，也就是只收到了 [33, 35) 和 [36, 38) 号数据。接收方发送回对报文段 A 的确认：ack = 35, win = 10。
- 发送方收到了 ack = 35, win = 10，对方期望接收 [35, 45) 号数据。接着发送了一个报文段 E，它携带了 [41, 44) 号数据。
- 接收方接收到了报文段 B: [35, 36), D:[38, 41)，接收方发送对 D 的确认：ack = 41, win = 10. （这是一个累积确认）
- 发送方收到了 ack = 41, win = 10，对方期望接收 [41, 51) 号数据。
- ......

需要注意的是，接收方接收 tcp 报文的顺序是不确定的，并非是一定先收到 35 再收到 36，也可能是先收到 36，37，再收到 35.

对于发送端的数据缓冲区有这些量：LastByteSent是目前发送的最后1字节的数据编号；LastByteAckd是目前接收到确认的最后1字节的数据编号；Rcvwin是窗口大小。鉴于每次发送方都是收到ACK之后滑动窗口继续发送，发送到LastByteSent这个位置，LastByteSent-LastByteAckd也就是这次发送数据的多少，那么只要满足：LastByteSent–LastByteAckd<=RcvWin(接收端空闲窗口大小) 就会保证不会溢出了。

那么接收端RcvWin怎么算呢？假设接收端缓冲区大小为RcvBuffer。LastByteRead：上层应用程序接收的最后一个字节序号，LastByteRcvd：接收端从网络接收的最后一个字节序号，那么LastByteRcvd–LastByteRead就是已经接受但是还没有传递给上层的数据。所以空闲区域RcvWin= RcvBuffer-(LastByteRcvd–LastByteRead).

### TCP 拥塞控制、慢启动、拥塞避免、快重传、快恢复

TCP发送方可能因为IP网络的拥塞而被遏制，TCP拥塞控制就是为了解决这个问题（注意和TCP流量控制区别）

TCP拥塞控制的几种方法：**慢启动，拥塞避免，快重传和快恢复**。

这里引入了一个**拥塞窗口**的概念：

拥塞窗口：发送方维持一个叫做拥塞窗口cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态变化。发送方的让自己的发送窗口=min（cwnd，接收端接收窗口大小）

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口旧增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口旧减小一些，以减少注入到网络中的分组数。

**慢启动**

当主机发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段确认后，把拥塞窗口增加至多一个MSS数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。

![img](../我的后端校招.assets/5679451-99fce3f0c67d8d9d.png)

每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。

另外，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。

```
为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下：
当 cwnd < ssthresh 时，使用上述的慢开始算法。
当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。
```

**拥塞避免**

让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。
 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。

如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。

![img](../我的后端校招.assets/5679451-30dd9996f5cee6c0.png)

<1>当TCP连接进行初始化时，把拥塞窗口cwnd置为1。前面已说过，为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即 cwnd = 16 。

<2>在执行慢开始算法时，拥塞窗口 cwnd 的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就把拥塞窗口值加1，然后开始下一轮的传输（图中横坐标为传输轮次）。因此拥塞窗口cwnd 随着传输轮次按指数规律增长。当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞控制算法，拥塞窗口按线 性规律增长。

<3>假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值 24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过 一个往返时间增加一个MSS的大小。

强调：<u>“拥塞避免”并非指完全能够避免了拥塞</u>。利用以上的措施要完全避免网络拥塞还是不可能的。<u>“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。</u>

**快重传**

在超时<u>重传</u>中，重点是<u>定时器溢出超时了才认为发送的数据包丢失</u>，<u>快速重传机制，实现了另外的一种丢包评定标准，即如果我连续收到3次重复ACK，发送方就认为这个seq的包丢失了，立刻进行重传</u>，这样如果接收端回复及时的话，基本就是在重传定时器到期之前，提高了重传的效率。

![img](../我的后端校招.assets/5679451-0138166a5ea7e0a4.png)

例如：M1，M2，M3 -----> M1,M3,缺失M2，则向发送方发送M2重复确认，当发送方收到M2的三次重复确认，则认为M2报文丢失，启动快重传机制，重传数据，其他数据发送数据放入队列，待快重传结束后再正常传输。

**快恢复**

与快重传配合使用的还有快恢复算法，其主要有以下两个要点：
 1）当发送方连续收到接收方发来的三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh减半（这个减半指的是变成发生阻塞时的阻塞窗口大小的一半），这是为了预防网络发生拥塞。（注意：接下来不执行慢开始算法）

2）由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是把cwnd(拥塞窗口)值设置为慢开始门限减半后的值（有些版本会让cwnd=ssthresh+3），然后开始执行拥塞避免算法，使拥塞窗口缓慢的线性增大。

![img](../我的后端校招.assets/5679451-97fdb861c78ac1b8.png)



### TCP 超时重传

原理时在发送某一个数据以后旧开启一个计时器，在一定时间内没有收到发送的数据报文的ACK报文，那么旧重新发送数据，直到发送成功为止。

影响超时重传机制协议效率的一个关键参数就是重传超时时间（RTO，Retransmission TImeOut），RTO的值被设置过大过小都会对协议造成不利影响。

1. RTO设长了，重发就很慢，没有效率，性能差
2. RTO设短了，重复很快，但是增加了网络拥塞，导致更多的超时，更多的超时导致更多的重发

连接往返时间（RTT，Round Trip Time），指发送端从发送TCP包开始到接收它的立即响应所消耗的时间。

RTO理论上最好就是网络的RTT时间，但又受制于网络距离与瞬态时延变化，所以实际上使用自适应的动态算法来确定超时时间。

### TCP 的四种定时器

TCP中有四种计时器（Timer），分别为：
 1.重传计时器：Retransmission Timer
 2.坚持计时器：Persistent Timer
 3.保活计时器：Keeplive Timer
 4.时间等待计时器：Timer_Wait Timer

（1）**重传计时器**
 大家都知道TCP是保证数据可靠传输的。怎么保证呢？带确认的重传机制。在滑动窗口协议中，接受窗口会在连续收到的包序列中的最后一个包向接收端发送一个ACK，当网络拥堵的时候，发送端的数据包和接收端的ACK包都有可能丢失。TCP为了保证数据可靠传输，就规定在重传的“时间片”到了以后，如果还没有收到对方的ACK，就重发此包，以避免陷入无限等待中。
 　当TCP发送报文段时，就创建该特定报文的重传计时器。可能发生两种情况：
 　1.若在计时器截止时间到之前收到了对此特定报文段的确认，则撤销此计时器。
 　2.若在收到了对此特定报文段的确认之前计时器截止时间到，则重传此报文段，并将计时器复位。

（2）**坚持计时器**
   专门对付零窗口通知而设立的，　　
   先来考虑一下情景：发送端向接收端发送数据包知道接受窗口填满了，然后接受窗口告诉发送方接受窗口填满了停止发送数据。此时的状态称为“零窗口”状态，发送端和接收端窗口大小均为0.直到接受TCP发送确认并宣布一个非零的窗口大小。但这个确认会丢失。我们知道TCP中，对确认是不需要发送确认的。若确认丢失了，接受TCP并不知道，而是会认为他已经完成了任务，并等待着发送TCP接着会发送更多的报文段。但发送TCP由于没有收到确认，就等待对方发送确认来通知窗口大小。双方的TCP都在永远的等待着对方。
   要打开这种死锁，TCP为每一个链接使用一个持久计时器。当发送TCP收到窗口大小为0的确认时，就坚持启动计时器。当坚持计时器期限到时，发送TCP就发送一个特殊的报文段，叫做探测报文。这个报文段只有一个字节的数据。他有一个序号，但他的序号永远不需要确认；甚至在计算机对其他部分的数据的确认时该序号也被忽略。探测报文段提醒接受TCP：确认已丢失，必须重传。
   坚持计时器的值设置为重传时间的数值。但是，若没有收到从接收端来的响应，则需发送另一个探测报文段，并将坚持计时器的值加倍和复位。发送端继续发送探测报文段，将坚持计时器设定的值加倍和复位，直到这个值增大到门限值（通常是60秒）为止。在这以后，发送端每个60秒就发送一个探测报文，直到窗口重新打开。
 （3）**保活计时器**
     保活计时器使用在某些实现中，用来防止在两个TCP之间的连接出现长时间的空闲。假定客户打开了到服务器的连接，传送了一些数据，然后就保持静默了。也许这个客户出故障了。在这种情况下，这个连接将永远的处理打开状态。
     要解决这种问题，在大多数的实现中都是使服务器设置保活计时器。每当服务器收到客户的信息，就将计时器复位。通常设置为两小时。若服务器过了两小时还没有收到客户的信息，他就发送探测报文段。若发送了10个探测报文段（每一个像个75秒）还没有响应，就假定客户除了故障，因而就终止了该连接。
 这种连接的断开当然不会使用四次握手，而是直接硬性的中断和客户端的TCP连接。
 （4）**时间等待计时器**
 　时间等待计时器是在四次握手的时候使用的。四次握手的简单过程是这样的：假设客户端准备中断连接，首先向服务器端发送一个FIN的请求关闭包（FIN=final），然后由established过渡到FIN-WAIT1状态。服务器收到FIN包以后会发送一个ACK，然后自己有established进入CLOSE-WAIT.此时通信进入半双工状态，即留给服务器一个机会将剩余数据传递给客户端，传递完后服务器发送一个FIN+ACK的包，表示我已经发送完数据可以断开连接了，就这便进入LAST_ACK阶段。客户端收到以后，发送一个ACK表示收到并同意请求，接着由FIN-WAIT2进入TIME-WAIT阶段。服务器收到ACK，结束连接。此时（即客户端发送完ACK包之后），客户端还要等待2MSL（MSL=maxinum segment lifetime最长报文生存时间，2MSL就是两倍的MSL）才能真正的关闭连接。

### TCP 粘包/拆包问题

在TCP编程中，我们使用协议(protocol)来解决粘包和拆包问题。

由于TCP传输协议面向流的，没有消息保护边界。一方发送的多个报文可能会被合并成一个大的报文进行传输，这就是粘包；也可能发送的一个报文，可能会被拆分成多个小报文，这就是拆包。

下图演示了粘包、拆包的过程，client分别发送了两个数据包D1和D2给server，server端一次读取到字节数是不确定的，因此可能可能存在以下几种情况：

1. server端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包
2. server一次接受到了两个数据包，D1和D2粘合在一起，称之为TCP粘包
3. server分两次读取到了数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这称之为TCP拆包
4. Server分两次读取到了数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余部分内容D1_2和完整的D2包。

 **由于发送方发送的数据，可能会发生粘包、拆包的情况。这样，对于接收端就难于分辨出来了，因此必须提供科学的机制来解决粘包、拆包问题，这就是协议的作用**。

**2 粘包、拆包产生的原因**

粘包、拆包问题的产生原因笔者归纳为以下3种：

- socket缓冲区与滑动窗口
- MSS/MTU限制
- Nagle算法

**2.1 socket缓冲区与滑动窗口**

​        每个TCP socket在内核中都有一个发送缓冲区(SO_SNDBUF )和一个接收缓冲区(SO_RCVBUF)，TCP的全双工的工作模式以及TCP的滑动窗口便是依赖于这两个独立的buffer的填充状态。

**SO_SNDBUF：**

进程发送的数据的时候假设调用了一个send方法，最简单情况（也是一般情况），将数据拷贝进入socket的内核发送缓冲区之中，然后send便会在上层返回。换句话说，send返回之时，数据不一定会发送到对端去（和write写文件有点类似），send仅仅是把应用层buffer的数据拷贝进socket的内核发送buffer中。

**SO_RCVBUF：**

把接受到的数据缓存入内核，应用进程一直没有调用read进行读取的话，此数据会一直缓存在相应socket的接收缓冲区内。再啰嗦一点，不管进程是否读取socket，对端发来的数据都会经由内核接收并且缓存到socket的内核接收缓冲区之中。read所做的工作，就是把内核缓冲区中的数据拷贝到应用层用户的buffer里面，仅此而已。

**滑动窗口：**

TCP连接在三次握手的时候，会将自己的窗口大小(window size)发送给对方，其实就是SO_RCVBUF指定的值。之后在发送数据的时，发送方必须要先确认接收方的窗口没有被填充满，如果没有填满，则可以发送。

每次发送数据后，发送方将自己维护的对方的window size减小，表示对方的SO_RCVBUF可用空间变小。

当接收方处理开始处理SO_RCVBUF 中的数据时，会将数据从socket 在内核中的接受缓冲区读出，此时接收方的SO_RCVBUF可用空间变大，即window size变大，接受方会以ack消息的方式将自己最新的window size返回给发送方，此时发送方将自己的维护的接受的方的window size设置为ack消息返回的window size。

此外，发送方可以连续的给接受方发送消息，只要保证对方的SO_RCVBUF空间可以缓存数据即可，即window size>0。当接收方的SO_RCVBUF被填充满时，此时window size=0，发送方不能再继续发送数据，要等待接收方ack消息，以获得最新可用的window size。

**2.2 MSS/MTU分片**

MTU  (Maxitum Transmission Unit,最大传输单元)是**链路层**对一次可以发送的最大数据的限制。MSS（Maxitum Segment Size,最大分段大小)是TCP报文中data部分的最大长度，是**传输层**对一次可以发送的最大数据的限制。

要了解MSS/MTU，首先需要回顾一下TCP/IP五层网络模型模型。

数据在传输过程中，每经过一层，都会加上一些额外的信息：

- **应用层：**只关心发送的数据DATA，将数据写入socket在内核中的缓冲区SO_SNDBUF即返回，操作系统会将SO_SNDBUF中的数据取出来进行发送。
- 传输层：会在DATA前面加上TCP Header(20字节)
- **网络层：**会在TCP报文的基础上再添加一个IP Header，也就是将自己的网络地址加入到报文中。IPv4中IP Header长度是20字节，IPV6中IP Header长度是40字节。
- **链路层：**加上Datalink Header和CRC。会将SMAC(Source Machine，数据发送方的MAC地址)，DMAC(Destination Machine，数据接受方的MAC地址 )和Type域加入。SMAC+DMAC+Type+CRC总长度为18字节。
- **物理层：**进行传输

在回顾这个基本内容之后，再来看MTU和MSS。MTU是以太网传输数据方面的限制，每个以太网帧最大不能超过1518bytes。刨去以太网帧的帧头(DMAC+SMAC+Type域）14Bytes和帧尾(CRC校验)4Bytes，**那么剩下承载上层协议的地方也就是Data域最大就只能有1500Bytes这个值 我们就把它称之为MTU**。

MSS是在MTU的基础上减去网络层的IP Header和传输层的TCP Header的部分，这就是TCP协议一次可以发送的实际应用数据的最大大小。

```javascript
MSS = MTU(1500) -IP Header(20 or 40)-TCP Header(20)
```

由于IPV4和IPV6的长度不同，在IPV4中，以太网MSS可以达到1460byte；在IPV6中，以太网MSS可以达到1440byte。

**发送方发送数据时，当SO_SNDBUF中的数据量大于MSS时，操作系统会将数据进行拆分，使得每一部分都小于MSS，也形成了拆包，**然后每一部分都加上TCP Header，构成多个完整的TCP报文进行发送，当然经过网络层和数据链路层的时候，还会分别加上相应的内容。

另外需要注意的是：对于本地回环地址(lookback)不需要走以太网，所以不受到以太网MTU=1500的限制。linux服务器上输入ifconfig命令，可以查看不同网卡的MTU大小，如下：

上图显示了2个网卡信息：

- eth0需要走以太网，所以MTU是1500；
- lo是本地回环，不需要走以太网，所以不受1500的限制。

**2.3 Nagle算法**

TCP/IP协议中，无论发送多少数据，总是要在数据(DATA)前面加上协议头(TCP Header+IP Header)，同时，对方接收到数据，也需要发送ACK表示确认。

**即使从键盘输入的一个字符，占用一个字节，可能在传输上造成41字节的包，其中包括1字节的有用信息和40字节的首部数据。这种情况转变成了4000%的消耗，这样的情况对于重负载的网络来是无法接受的。称之为"糊涂窗口综合征"**。

为了尽可能的利用网络带宽，TCP总是希望尽可能的发送足够大的数据。（一个连接会设置MSS参数，因此，TCP/IP希望每次都能够以MSS尺寸的数据块来发送数据）。Nagle算法就是为了尽可能发送大块数据，避免网络中充斥着许多小数据块。

Nagle算法的基本定义是任意时刻，最多只能有一个未被确认的小段。 所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。

Nagle算法的规则：

1. 如果SO_SNDBUF中的数据长度达到MSS，则允许发送；
2. 如果该SO_SNDBUF中含有FIN，表示请求关闭连接，则先将SO_SNDBUF中的剩余数据发送，再关闭；
3. 设置了TCP_NODELAY=true选项，则允许发送。TCP_NODELAY是取消TCP的确认延迟机制，相当于禁用了Negale 算法。正常情况下，当Server端收到数据之后，它并不会马上向client端发送ACK，而是会将ACK的发送延迟一段时间（假一般是40ms），它希望在t时间内server端会向client端发送应答数据，这样ACK就能够和应答数据一起发送，就像是应答数据捎带着ACK过去。当然，TCP确认延迟40ms并不是一直不变的，TCP连接的延迟确认时间一般初始化为最小值40ms，随后根据连接的重传超时时间（RTO）、上次收到数据包与本次接收数据包的时间间隔等参数进行不断调整。另外可以通过设置TCP_QUICKACK选项来取消确认延迟。
4. 未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送;
5. 上述条件都未满足，但发生了超时（一般为200ms），则立即发送。

**3 通信协议**

在了解了粘包、拆包产生的原因之后，现在来分析接收方如何对此进行区分。道理很简单，如果存在不完整的数据(拆包)，则需要继续等待数据，直至可以构成一条完整的请求或者响应。

**通过定义通信协议(protocol)，可以解决粘包、拆包问题。协议的作用就定义传输数据的格式。**这样在接受到的数据的时候：

- 如果粘包了，就可以根据这个格式来区分不同的包
- 如果拆包了，就等待数据可以构成一个完整的消息来处理。

**3.1 定长协议**

​        定长协议：顾名思义，就是指定一个报文的必须具有固定的长度。例如，我们规定每3个字节，表示一个有效报文，如果我们分4次总共发送以下9个字节：

```javascript
  +---+----+------+----+  | A | BC | DEFG | HI |  +---+----+------+----+
```

​     那么根据协议，我们可以判断出来，这里包含了3个有效的请求报文，如下：

```javascript
   +-----+-----+-----+   | ABC | DEF | GHI |   +-----+-----+-----+
```

在定长协议中：

- 发送方，必须保证发送报文长度是固定的。如果报文字节长度不能满足条件，如规定长度是1024字节，但是实际需要发送的内容只有900个字节，那么不足的部分可以补充0。因此定长协议可能会浪费带宽。
- 接收方，每读取到固定长度的内容时，则认为读取到了一个完整的报文。

**提示：**Netty中提供了FixedLengthFrameDecoder，支持把固定的长度的字节数当做一个完整的消息进行解码

**3.2 特殊字符分隔符协议**

在包尾部增加回车或者空格符等特殊字符进行分割 。例如，按行解析，遇到字符\n、\r\n的时候，就认为是一个完整的数据包。对于以下二进制字节流：

```javascript
   +--------------+   | ABC\nDEF\r\n |   +--------------+
```

那么根据协议，我们可以判断出来，这里包含了2个有效的请求报文

```javascript
   +-----+-----+   | ABC | DEF |   +-----+-----+
```

​        在特殊字符分隔符协议中：

- 发送方，需要在发送一个报文时，需要在报文尾部添加特殊分割符号；
- 接收方，在接收到报文时，需要对特殊分隔符进行检测，直到检测到一个完整的报文时，才能进行处理。

**在使用特殊字符分隔符协议的时候，需要注意的是，我们选择的特殊字符，一定不能在消息体中出现，否则可能会出现错误的拆包。**例如，发送方希望把”12\r\n34”，当成一个完整的报文，如果是按行拆分，那么就会错误的拆分为2个报文。一种解决策略是，发送方对需要发送的内容预先进行base64编码，由于base64编码只包含64个字符：0-9、a-z、A-Z、+、/，我们可以选择这64个字符之外的特殊字符作为分隔符。

**提示：**netty中提供了DelimiterBasedFrameDecoder根据特殊字符进行解码。事实上，我们熟悉的的缓存服务器redis，也是通过换行符来区分一个完整的报文。

**3.3 变长协议**

将消息区分为消息头和消息体，在消息头中，我们使用一个整形数字，例如一个int，来表示消息体的长度。而消息体实际实际要发送的二进制数据字节。以下是一个基本格式：

```javascript
  header    body+--------+----------+| Length |  Content |+--------+----------+
```

在变长协议中：

- 发送方，发送数据之前，需要先获取需要发送内容的二进制字节大小，然后在需要发送的内容前面添加一个整数，表示消息体二进制字节的长度。
- 接收方，在解析时，先读取内容长度Length，其值为实际消息体内容(Content)占用的字节数，之后必须读取到这么多字节的内容，才认为是一个完整的数据报文。

**提示：**Netty中提供了LengthFieldPrepender给实际内容Content进行编码添加Length字段，接受方使用LengthFieldBasedFrameDecoder解码。

**3.4 序列化**

​        序列化本质上已经不是为了解决粘包和拆包问题，而是为了在网络开发中可以更加的便捷。在变长协议中，我们看到可以在实际要发送的数据之前加上一个length字段，表示实际要发送的数据的长度。**这实际上给我们了一个很好的思路，我们完全可以将一个对象转换成二进制字节，来进行通信，例如使用一个Request对象表示请求，使用一个Response对象表示响应**。

​        序列化框架有很多种，我们在选择时，主要考虑序列化/反序列化的速度，序列化占用的体积，多语言支持等。下面列出了业界流行的序列化框架：

| 框架             | 支持语言                | 官网                                                  |
| :--------------- | :---------------------- | :---------------------------------------------------- |
| jdk序列化        | Java                    |                                                       |
| hessian          | 支持多种，不包含go      | http://hessian.caucho.com/                            |
| fst              | Java                    | https://github.com/RuedigerMoeller/fast-serialization |
| protobuf         | 几乎所有主流语言        | https://developers.google.cn/protocol-buffers/        |
| protostuff       | Java                    | https://protostuff.github.io/                         |
| avro             | Java、c\c++、c#、python | http://avro.apache.org                                |
| kyro             | java                    | https://github.com/EsotericSoftware/kryo              |
| msgback          | 几乎所有主流语言        | https://msgpack.org/                                  |
| thrift           | 几乎所有主流语言        | http://thrift.apache.org/                             |
| JBoss Marshlling | java                    | http://jbossmarshalling.jboss.org/                    |

**提示：**xml、json也属于序列化框架的范畴，上面的表格中并没有列出。

一些网络通信的RPC框架通常会支持多种序列化方式，例如dubbo支持hessian、json、kyro、fst等。在支持多种序列化框架的情况下，在协议中通常需要有一个字段来表示序列化的类型，例如，我们可以将上述变长协议的格式改造为：

```javascript
+--------+-------------+------------+| Length |  serializer |   Content  |+--------+-------------+------------+
```

   这里使用1个字节表示Serializer的值，使用不同的值代表不同的框架。

- 发送方，选择好序列化框架后编码后，需要指定Serializer字段的值。
- 接收方，在解码时，根据Serializer的值选择对应的框架进行反序列化；

**3.5 压缩**

通常，为了节省网络开销，在网络通信时，可以考虑对数据进行压缩。常见的压缩算法有lz4、snappy、gzip等。在选择压缩算法时，我们主要考虑压缩比以及解压缩的效率。

我们可以在网络通信协议中，添加一个compress字段，表示采用的压缩算法：

```javascript
+--------+-----------+------------+------------+| Length | serializer|  compress  |   Content  |+--------+-----------+------------+------------+
```

通常，我们没有必要使用一个字节，来表示采用的压缩算法，1个字节可以标识256种可能情况，而常用压缩算法也就那么几种，因此通常只需要使用2~3个bit来表示采用的压缩算法即可。

另外，由于数据量比较小的时候，压缩比并不会太高，没有必要对所有发送的数据都进行压缩，只有再超过一定大小的情况下，才考虑进行压缩。如rocketmq，producer在发送消息时，默认消息大小超过4k，才会进行压缩。因此，compress字段，应该有一个值，表示没有使用任何压缩算法，例如使用0。

**3.6 查错校验码**

一些通信协议传输的数据中，还包含了查错校验码。典型的算法如CRC32、Adler32等。java对这两种校验方式都提供了支持，java.util.zip.Adler32、java.util.zip.CRC32。

```javascript
+--------+-----------+------------+------------+---------+| Length | serializer|  compress  |   Content  |  CRC32  |+--------+-----------+------------+------------+---------+
```

这里并不对CRC32、Adler32进行详细说明，主要是考虑，为什么需要进行校验？

有人说是因为考虑到安全，这个理由似乎并不充分，因为我们已经有了TLS层的加密，CRC32、Adler32的作用不应该是为了考虑安全。

一位同事的观点，我非常赞同：二进制数据在传输的过程中，可能因为电磁干扰，导致一个高电平变成低电平，或者低电平变成高电平。这种情况下，数据相当于受到了污染，此时通过CRC32等校验值，则可以验证数据的正确性。

另外，通常校验机制在通信协议中，是可选的配置的，并不需要强制开启，其虽然可以保证数据的正确，但是计算校验值也会带来一些额外的性能损失。如Mysql主从同步，虽然高版本默认开启CRC32校验，但是也可以通过配置禁用。

**3.7 小结**

本节通过一些基本的案例，讲解了在TCP编程中，如何通过协议来解决粘包、拆包问题。在实际开发中，通常我们的协议会更加复杂。例如，一些RPC框架，会在协议中添加唯一标识一个请求的ID，一些支持双向通信的RPC框架，如sofa-bolt，还会添加一个方向信息等。当然，所谓复杂，无非是在协议中添加了某个字段用于某个用途，只要弄清楚这些字段的含义，也就不复杂了。



### 参考

https://www.jianshu.com/p/8c5ccbe51f5b

https://cloud.tencent.com/developer/article/1430021



---



## UDP

### TCP 与 UDP 的区别

1. TCP 面向连接，UDP 是无连接的；
2. TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付
3. TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道
4. 每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信
5. TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）
6. UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）
7. TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节

---



## HTTP

##### OPTIONS

**options在什么情况下出现**

- **跨域** 调用，例如：调试时候很多情况都在跨越方式下调试;
- 自定义头部
- 请求头的content-type参数：application/x-www-form-urlencoded，multipart/form-data，text/plain之外的格式

以上三种情况出现就会出现options请求了，说白就是为了服务器安全，例如：同源策略引发这个规则;

options通常是浏览器自动发起的，目的就是去服务器检查一下接下来要到用的方法(GET、POST、PUT、detele)在服务器上是否支持;

**对于服务器该如何处理**

检查以下内容

**A：方式**

- 来源是否允许
- 自定义的头部是否包含(这个和你项目有关)

如果你项目认为是安全的，直接返回200状态码，就可以;

**B：方式**

- 来源是否允许
- 自定义的头部是否包含(这个和你项目有关)
- 检查content-type 的内容是否是你期望的

如果你项目认为是安全的，直接返回200状态码，就可以

如果不允许你可以放回状态码400或者其他;

**options请求影响服务性能，如何优化**

本来一个请求就搞定，结果频繁多了很多options必然造成服务的压力;

可以做到options请求做缓存处理，例如： http:// www.**.com/api/getUser 接口会出现   options请求，我们在options返回是做一次options缓存，告知前端以后在此请求这个接口就不要在发options了，服务器响应时可设置  Access-Control-Max-Age 的时间，默认10分钟;

---

